{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkBKyUIPhSxE",
        "outputId": "ebe529de-eaa5-4841-f3c9-530bb80cd352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.13.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_lightning-2.5.1.post0 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTGiXcoHhYU5",
        "outputId": "c63c179e-bb19-4cbc-b8c9-dde09a36d169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994,
          "referenced_widgets": [
            "cdee24d0b0344bb1a78e4ab167e17c4f",
            "f868686f8b804520ba5e290cce263aec",
            "19c7799314ab4bf3baf9e254118ee878",
            "216310b49fa841ac908f968650d1b2ad",
            "8807f20f503843a2a5bfa91d4971fd42",
            "bd11f6f7286e4ca09c0f603b248f900a",
            "61befa075bd4401695f706b274d97d36",
            "73eaacd4b32747f89ad7dde56df3d260",
            "ded35efdcbec4282946c438b4f48f437",
            "f24cd55c77444b23a8d34a5b179f4bda",
            "d1a2e00252224a7badf133f7152c036e",
            "4313221fab5e4c5c8f25c3b7d81bb8bf",
            "ec73da42910a4b9595a46ef2052720b5",
            "f67c7adedd544d1788df8ae6f6cbe03f",
            "7888eec270e74c8581292e9f1a1525b5",
            "49b507795fc34667ac928198e6c11282",
            "5de2a9d59f2d42be8740325e7d56a87e",
            "1b07094141994942bd41852092f5574d",
            "a47e873d0e454b4883fda3acf7a8343d",
            "747d414c46bd47afbb18db73b3b1153c",
            "377bc3ccdd3949969f52d606501929d6",
            "c1207a845a144d4eafc14798f5ce68a2",
            "5cc5365a9a6544fa8558e6987857ba70",
            "e2554d6bf5934e2589558e173ca70f7c",
            "b2e5efb6c4ac4320be6e831f9841db8f",
            "f99f7aeea5894135863056c105ec3a7e",
            "00c7e6cae7944ad7bc1becfd2a804033",
            "a5a79647373b4b88a4c107a95d53ad6a",
            "c2981fe8584049cc8a1f4a7fe928e503",
            "01c9e8c9d42a4a92a9274ffdf0f14644",
            "fddd98bc924c4babaa2392c3446ed921",
            "684999195aa04a57abdd850767853915",
            "cbb6e7bb7994445b925b3cb98f60ab1b",
            "90cda0e113984bd5a358c24a06f87720",
            "1a7ba54f9dfd4f918c05e84c21ff5d08",
            "87656b0c16ed45e0ac60a27a1a1ab877",
            "a046dc182cb640d197139dba277d0dde",
            "533c1daa984f4bb5870887ec6305ad91",
            "b3fc7910b7cf4588933a3654aa477c46",
            "7c3105c3123241a492b285381f6032a1",
            "0f00e4f864c146288b9f5159a01c3ca2",
            "c0ee6d63cf45455abf0ee6ab7f877b63",
            "b227a80e9b7742c19a1a8f809b47ceae",
            "f9d73249784f45e0b1dbc1a1be5504ac",
            "31adcc301efb4e51967357a4b0b1a248",
            "15caccb494c5474cafceb1b1081883c2",
            "d8aa6f8874f74b7dbb03741b34cb295b",
            "b7349d4f96bc4f7d893ac1e823f723eb",
            "334d42be7b604aea961c67122f5223fe",
            "1798665bfabb487cbf960aa1e9678958",
            "d80da0521f40498081fac4a3c211b8e7",
            "8741e2b4627f48e6b30e007bac8350d7",
            "bf1e0d0474d74d6cab927c481f589e4e",
            "863823a533c74128aa6b372502188aa4",
            "ee6739e0ab7943e8b4e386615bebc704",
            "468468f905fd42f0aff597c8f7d1f89a",
            "e056365c421c4309b4d0cb0d36ffe226",
            "b91abd4ac46f428eb1cb48c0d354706b",
            "4afcf0779b7e4299aefc64414d9ee927",
            "5544431dab22411fa044095165c5e75d",
            "350fcfe5ef1840248eae4c5586d32b05",
            "15c00de5e4f2476db9f9dcf285958d44",
            "76609eb86cd64b51893727c64ec095e6",
            "e076203209ef489fa6672d751aa45884",
            "49ccaa13349d4584a91d168739ef8014",
            "23f6557c3bed43d88eca4228509cad42",
            "76387a377f054bd4b3a5695247311e72",
            "88e6e48f828946529e7ac3acbcbfb28f",
            "2c4ca81f1ad44396ac5b89bb16b1893f",
            "ea3b2a78260247c6b8bd85a2d59b0d37",
            "b98b1613b72c4004aa51e18f04830de6",
            "622cb7c297834e8a979e146102b71f68",
            "837cc0ac431d445eaf9db21fbee05f90",
            "dccabd1f01d645c1ad7fbc2b233e0f36",
            "a65f7a40361f4868899c079ddd7d62eb",
            "67475f179985476fa440a64ed9e045d8",
            "247809d6dd4b4f4682b61ee8ed77319f",
            "145b6c189241462ca41fefedb0aa49eb",
            "9c0c8fa681934eddadc2735d1f57c644",
            "cb881f5d0a7e4ecaad4f0578613878e7",
            "38528d57affc49378b3d374e562c1d67",
            "f85c22d9eb3245cc82ff84946bf0ba55",
            "a730b46b74b5421a9a178d92b731c81b",
            "1f9efb085ccb43d8971472128509fed8",
            "a48d469fcd304bcfa5e33f3314b79806",
            "3c4f4f19ec7d47fe8b0cc31ff3b02db6",
            "67bce420d3d9452b847528fc6f0477a9",
            "c92d7739330c48da85b40c6ecb149ed6",
            "5b95cd14774c4fccb1889c9d7c64a63f",
            "e7cd139a88af4b7bb35b11d0ef2a2f11",
            "150e2777079840e6a3dc838495d3d280",
            "b3b914be596042d3a5d5b555d3579ff9",
            "f4e61c3b20e941d9807e4426015014a1",
            "49b12710290244b495d909f08d8fbe19",
            "168a729b38cc46e0a9ca8f4ae88d4314",
            "3f4d7c67d8a7430c9a373d5c3dd1380b",
            "17623b98e6ac4bb893ca68e528ffb13c",
            "a12977625c7e46b384099664dc06ff36",
            "a4d5418a54cc446480c93f70b8eec598",
            "bdf5165cd23b46fd9587945527e5878d",
            "99d005899fb044a498b5bf3d080caa16",
            "956c13228679431e9b0b2847d3ddba77",
            "2aef354282a146b396729dd3da5e6b70",
            "12e782c9492b4a5c8cb9d2c5fad9400b",
            "48bd8f7955504ff1b3f2d450ee66a403",
            "0fe948270a2c4cd88cf0e7df6ba4c04d",
            "2d3b9cd3a13a414ca54684ae1f5422c7",
            "d009ce532195459f90cf4940583eb60a",
            "40a058d918344e3691c6fc18d58b090f",
            "92cc3bf18eb2476e8249228a82f32c11",
            "580f64f2d1794363ba879201c2bdb6d2",
            "893581e42d96456987a295127b3b0e04",
            "b7765bfffdfa426da1532c7ae3a78255",
            "67b07d63981b4c29950b3af6b335790e",
            "7a876e5cd71b4a3282b42c534c4e4f93",
            "bee9ab98985d428cafa9fe8268561df0",
            "945642010afc457a85a06cafd4ab1344",
            "31c702446b464d1c93750c252a283b8d",
            "eb4a0d6ada944b6ba5ef632a8a0eb98e",
            "259c348e3dff48fab0b9eedc95e5a032",
            "0307dcd25c9d4696964f9bc9cda5ca6d",
            "390e5525883d42a1b734f01cea0fc9c7",
            "469934f2d11649d1ba49770c8cf314a8",
            "cbc3e572565c48b1ae29cbe177baadc6",
            "e8aee2494b8240cd936a4c926aa94d59",
            "08cfe432ab184c9f83a241f78d389b8c",
            "0bb4c695506d44dab7192dc9d7382cc5",
            "aed09bd81a384348a68a48e608ef65ab",
            "6328b768b048451493aca8a6cdea2a8e",
            "c5de74851fca4eccbd532555a6cef851",
            "de7d18fd629c48c99c3575710d0a62b4",
            "e75486bc41f04f4a8943d30bbdd6c412",
            "b0470eed5572414d9bbad3a3c94de920",
            "33673f4ecbba48f8a4c85e71d8c2c884",
            "7fcecdea0b8c4db799f121fa1ddf75b2",
            "1e724b8a5069497da342bca20997c5ce",
            "645e86a8c8034f49bf7bc6cf55b91a4b",
            "a344adaac4a24ba0bb2a903f2269f182",
            "3c953b72f21546e89fdb13d08c965802",
            "fe76bb49f44f4bf0890760131b632c58",
            "f5ba7ac0633947098decc90fe1052ff7",
            "a89c42a79fcd42038b963f497b7f5ad1",
            "2e3c81e0189a4cc1bc786c87e3bfefe1"
          ]
        },
        "id": "WyqKC2lsg5gU",
        "outputId": "e2c6334a-3003-4a64-9c64-f988be6f10d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "Torchvision version: 0.21.0+cu124\n",
            "Using device: cpu\n",
            "Creating synthetic chest X-ray dataset...\n",
            "Created synthetic dataset with 100 normal and 100 pneumonia X-rays\n",
            "Training samples: 160\n",
            "Validation samples: 40\n",
            "Training class distribution: [80 80]\n",
            "Validation class distribution: [20 20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44.7M/44.7M [00:01<00:00, 36.3MB/s]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using class weight: 1.0\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name           | Type              | Params | Mode \n",
            "-------------------------------------------------------------\n",
            "0 | model          | ResNet            | 11.2 M | train\n",
            "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
            "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
            "3 | val_accuracy   | BinaryAccuracy    | 0      | train\n",
            "4 | val_f1         | BinaryF1Score     | 0      | train\n",
            "5 | val_auroc      | BinaryAUROC       | 0      | train\n",
            "-------------------------------------------------------------\n",
            "11.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.2 M    Total params\n",
            "44.683    Total estimated model params size (MB)\n",
            "73        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdee24d0b0344bb1a78e4ab167e17c4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
            "  warnings.warn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4313221fab5e4c5c8f25c3b7d81bb8bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cc5365a9a6544fa8558e6987857ba70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90cda0e113984bd5a358c24a06f87720"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31adcc301efb4e51967357a4b0b1a248"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "468468f905fd42f0aff597c8f7d1f89a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76387a377f054bd4b3a5695247311e72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "145b6c189241462ca41fefedb0aa49eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b95cd14774c4fccb1889c9d7c64a63f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdf5165cd23b46fd9587945527e5878d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "580f64f2d1794363ba879201c2bdb6d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "390e5525883d42a1b734f01cea0fc9c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model path: /content/lightning_logs/version_0/checkpoints/pneumonia-epoch=09-val_acc_epoch=0.859.ckpt\n",
            "Best validation accuracy: 0.8591\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0470eed5572414d9bbad3a3c94de920"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       1.00      1.00      1.00        20\n",
            "   Pneumonia       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n",
            "Analysis complete!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Pneumonia Classification with ResNet18\n",
        "=====================================\n",
        "This script builds and trains a ResNet18-based model to classify chest X-rays for pneumonia detection.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import torchmetrics\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Torchvision version:\", torchvision.__version__)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create directories for the dataset\n",
        "data_dir = './data/chest_xray'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# For this example, we'll use a synthetic dataset with random noise\n",
        "# In a real scenario, you would use real X-ray images\n",
        "def create_synthetic_dataset(data_dir, num_normal=100, num_pneumonia=100):\n",
        "    \"\"\"Create a synthetic dataset of 'chest X-rays' for demonstration\"\"\"\n",
        "    # Create directories\n",
        "    train_normal_dir = os.path.join(data_dir, 'train', 'NORMAL')\n",
        "    train_pneumonia_dir = os.path.join(data_dir, 'train', 'PNEUMONIA')\n",
        "    val_normal_dir = os.path.join(data_dir, 'val', 'NORMAL')\n",
        "    val_pneumonia_dir = os.path.join(data_dir, 'val', 'PNEUMONIA')\n",
        "\n",
        "    for directory in [train_normal_dir, train_pneumonia_dir, val_normal_dir, val_pneumonia_dir]:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Generate synthetic normal images (more uniform)\n",
        "    for i in range(int(num_normal * 0.8)):  # 80% for training\n",
        "        img = np.random.normal(0.5, 0.1, (224, 224))  # Gaussian noise with higher mean\n",
        "        img = np.clip(img, 0, 1)  # Clip values to be between 0 and 1\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        Image.fromarray(img).save(os.path.join(train_normal_dir, f'normal_{i}.png'))\n",
        "\n",
        "    for i in range(int(num_normal * 0.2)):  # 20% for validation\n",
        "        img = np.random.normal(0.5, 0.1, (224, 224))\n",
        "        img = np.clip(img, 0, 1)\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        Image.fromarray(img).save(os.path.join(val_normal_dir, f'normal_{i}.png'))\n",
        "\n",
        "    # Generate synthetic pneumonia images (more textured with random patches)\n",
        "    for i in range(int(num_pneumonia * 0.8)):  # 80% for training\n",
        "        # Base image\n",
        "        img = np.random.normal(0.4, 0.1, (224, 224))\n",
        "\n",
        "        # Add random patches to simulate pneumonia opacity\n",
        "        num_patches = np.random.randint(3, 8)\n",
        "        for _ in range(num_patches):\n",
        "            x = np.random.randint(20, 200)\n",
        "            y = np.random.randint(20, 200)\n",
        "            size = np.random.randint(20, 60)\n",
        "            intensity = np.random.uniform(0.7, 0.9)  # Brighter patch\n",
        "\n",
        "            # Create a circular patch\n",
        "            for i_x in range(max(0, x-size), min(224, x+size)):\n",
        "                for i_y in range(max(0, y-size), min(224, y+size)):\n",
        "                    if (i_x - x)**2 + (i_y - y)**2 < size**2:\n",
        "                        img[i_y, i_x] = intensity\n",
        "\n",
        "        img = np.clip(img, 0, 1)\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        Image.fromarray(img).save(os.path.join(train_pneumonia_dir, f'pneumonia_{i}.png'))\n",
        "\n",
        "    for i in range(int(num_pneumonia * 0.2)):  # 20% for validation\n",
        "        # Base image\n",
        "        img = np.random.normal(0.4, 0.1, (224, 224))\n",
        "\n",
        "        # Add random patches\n",
        "        num_patches = np.random.randint(3, 8)\n",
        "        for _ in range(num_patches):\n",
        "            x = np.random.randint(20, 200)\n",
        "            y = np.random.randint(20, 200)\n",
        "            size = np.random.randint(20, 60)\n",
        "            intensity = np.random.uniform(0.7, 0.9)\n",
        "\n",
        "            # Create a circular patch\n",
        "            for i_x in range(max(0, x-size), min(224, x+size)):\n",
        "                for i_y in range(max(0, y-size), min(224, y+size)):\n",
        "                    if (i_x - x)**2 + (i_y - y)**2 < size**2:\n",
        "                        img[i_y, i_x] = intensity\n",
        "\n",
        "        img = np.clip(img, 0, 1)\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        Image.fromarray(img).save(os.path.join(val_pneumonia_dir, f'pneumonia_{i}.png'))\n",
        "\n",
        "    print(f\"Created synthetic dataset with {num_normal} normal and {num_pneumonia} pneumonia X-rays\")\n",
        "\n",
        "    # Calculate dataset statistics\n",
        "    mean_val = 0.5  # Approximate mean for our synthetic data\n",
        "    std_val = 0.2   # Approximate std for our synthetic data\n",
        "\n",
        "    return mean_val, std_val\n",
        "\n",
        "# Create the synthetic dataset\n",
        "print(\"Creating synthetic chest X-ray dataset...\")\n",
        "mean_val, std_val = create_synthetic_dataset(data_dir)\n",
        "\n",
        "# Define transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_val, std_val),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=(-5, 5),\n",
        "        translate=(0, 0.05),\n",
        "        scale=(0.9, 1.1)\n",
        "    ),\n",
        "    transforms.RandomResizedCrop((224, 224), scale=(0.8, 1.0))\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_val, std_val)\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ImageFolder(\n",
        "    os.path.join(data_dir, 'train'),\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "val_dataset = ImageFolder(\n",
        "    os.path.join(data_dir, 'val'),\n",
        "    transform=val_transforms\n",
        ")\n",
        "\n",
        "# Display dataset information\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "# Display class distribution\n",
        "train_counts = np.bincount(train_dataset.targets)\n",
        "val_counts = np.bincount(val_dataset.targets)\n",
        "print(f\"Training class distribution: {train_counts}\")\n",
        "print(f\"Validation class distribution: {val_counts}\")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# Define the PyTorch Lightning model\n",
        "class XrayClassifier(pl.LightningModule):\n",
        "    def __init__(self, class_weight=1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load the pre-trained ResNet18\n",
        "        self.model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "        # Modify the first layer to accept grayscale images\n",
        "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Modify the final layer for binary classification\n",
        "        self.model.fc = nn.Linear(512, 1)\n",
        "\n",
        "        # Set up loss function and metrics\n",
        "        self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weight]))\n",
        "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "        self.val_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "\n",
        "        # Add F1 Score and AUROC metrics\n",
        "        self.val_f1 = torchmetrics.F1Score(task=\"binary\")\n",
        "        self.val_auroc = torchmetrics.AUROC(task=\"binary\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y = y.float()\n",
        "        logits = self(x).squeeze(1)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        # Log metrics\n",
        "        self.log(\"train_loss\", loss)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        self.log(\"train_acc_step\", self.train_accuracy(probs, y.int()))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"train_acc_epoch\", self.train_accuracy.compute())\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y = y.float()\n",
        "        logits = self(x).squeeze(1)\n",
        "        loss = self.criterion(logits, y)\n",
        "\n",
        "        # Log metrics\n",
        "        self.log(\"val_loss\", loss)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        self.log(\"val_acc_step\", self.val_accuracy(probs, y.int()))\n",
        "        self.log(\"val_f1\", self.val_f1(probs, y.int()))\n",
        "        self.log(\"val_auroc\", self.val_auroc(probs, y.int()))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"val_acc_epoch\", self.val_accuracy.compute())\n",
        "        self.log(\"val_f1_epoch\", self.val_f1.compute())\n",
        "        self.log(\"val_auroc_epoch\", self.val_auroc.compute())\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Use Adam optimizer with a learning rate scheduler\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-4)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='max',\n",
        "            factor=0.5,\n",
        "            patience=2,\n",
        "            verbose=True\n",
        "        )\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"monitor\": \"val_acc_epoch\",\n",
        "                \"interval\": \"epoch\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Create the model - compute class weight based on dataset imbalance\n",
        "weight = train_counts[0] / train_counts[1] if len(train_counts) > 1 else 1.0\n",
        "model = XrayClassifier(class_weight=weight)\n",
        "print(f\"Using class weight: {weight}\")\n",
        "\n",
        "# Create callbacks\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_acc_epoch',\n",
        "    save_top_k=3,\n",
        "    mode='max',\n",
        "    filename='pneumonia-{epoch:02d}-{val_acc_epoch:.3f}'\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=10,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    log_every_n_steps=10,\n",
        "    accelerator='auto',  # Use GPU if available\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "# Print best model path\n",
        "print(f\"Best model path: {checkpoint_callback.best_model_path}\")\n",
        "print(f\"Best validation accuracy: {checkpoint_callback.best_model_score:.4f}\")\n",
        "\n",
        "# Load the best model for evaluation\n",
        "best_model = XrayClassifier.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
        "best_model.eval()\n",
        "best_model.to(device)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_preds = []\n",
        "val_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "        x = x.to(device)\n",
        "        logits = best_model(x).squeeze(1)\n",
        "        preds = torch.sigmoid(logits).cpu().numpy()\n",
        "        val_preds.extend(preds)\n",
        "        val_labels.extend(y.numpy())\n",
        "\n",
        "val_preds = np.array(val_preds)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "val_pred_binary = (val_preds > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(val_labels, val_pred_binary)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "classes = ['Normal', 'Pneumonia']\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, str(cm[i, j]),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.savefig('confusion_matrix.png')\n",
        "plt.close()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_labels, val_pred_binary, target_names=classes))\n",
        "\n",
        "# ROC curve and AUC\n",
        "fpr, tpr, _ = roc_curve(val_labels, val_preds)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig('roc_curve.png')\n",
        "plt.close()\n",
        "\n",
        "# Visualize some predictions\n",
        "plt.figure(figsize=(15, 10))\n",
        "indices = np.random.choice(len(val_dataset), 8, replace=False)\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    img, label = val_dataset[idx]\n",
        "    img_tensor = img.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logit = best_model(img_tensor).item()\n",
        "        prob = torch.sigmoid(torch.tensor(logit)).item()\n",
        "\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.imshow(img[0], cmap='bone')\n",
        "    predicted = \"Pneumonia\" if prob > 0.5 else \"Normal\"\n",
        "    true_label = \"Pneumonia\" if label == 1 else \"Normal\"\n",
        "    color = \"green\" if predicted == true_label else \"red\"\n",
        "    plt.title(f\"Pred: {predicted} ({prob:.2f})\\nTrue: {true_label}\", color=color)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('predictions.png')\n",
        "plt.close()\n",
        "\n",
        "# Implement Grad-CAM for explainability\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "        # Register hooks\n",
        "        target_layer.register_forward_hook(self.save_activation)\n",
        "        target_layer.register_full_backward_hook(self.save_gradient)\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output.detach()\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "\n",
        "    def __call__(self, x, class_idx=None):\n",
        "        # Forward pass\n",
        "        x = x.to(device)\n",
        "        self.model.zero_grad()\n",
        "        output = self.model(x).squeeze()\n",
        "\n",
        "        # If class_idx is None, use the predicted class\n",
        "        if class_idx is None:\n",
        "            class_idx = torch.sigmoid(output) > 0.5\n",
        "\n",
        "        # Backward pass\n",
        "        output.backward()\n",
        "\n",
        "        # Get weights\n",
        "        gradients = self.gradients\n",
        "        activations = self.activations\n",
        "\n",
        "        # Global average pooling\n",
        "        weights = torch.mean(gradients, dim=(2, 3))\n",
        "\n",
        "        # Create CAM\n",
        "        batch_size, channels, height, width = activations.shape\n",
        "        cam = torch.zeros((batch_size, height, width), dtype=torch.float32, device=device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            # Weighted sum of activation maps\n",
        "            for j in range(channels):\n",
        "                cam[i] += weights[i, j] * activations[i, j]\n",
        "\n",
        "            # ReLU\n",
        "            cam[i] = torch.maximum(cam[i], torch.tensor(0.0, device=device))\n",
        "\n",
        "            # Normalize\n",
        "            if torch.max(cam[i]) > 0:\n",
        "                cam[i] = cam[i] / torch.max(cam[i])\n",
        "\n",
        "        return cam\n",
        "\n",
        "# Create Grad-CAM visualizations\n",
        "# Get the last convolutional layer in ResNet18\n",
        "target_layer = best_model.model.layer4[-1].conv2\n",
        "\n",
        "# Initialize Grad-CAM\n",
        "grad_cam = GradCAM(best_model, target_layer)\n",
        "\n",
        "# Visualize some examples with Grad-CAM\n",
        "plt.figure(figsize=(15, 10))\n",
        "indices = np.random.choice(len(val_dataset), 4, replace=False)\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    img, label = val_dataset[idx]\n",
        "    img_tensor = img.unsqueeze(0).to(device)\n",
        "\n",
        "    # Get model prediction\n",
        "    with torch.no_grad():\n",
        "        logit = best_model(img_tensor).item()\n",
        "        prob = torch.sigmoid(torch.tensor(logit)).item()\n",
        "\n",
        "    # Get Grad-CAM\n",
        "    # We need to run this with gradients enabled\n",
        "    cam = grad_cam(img_tensor)\n",
        "    cam = cam[0].cpu().numpy()\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.imshow(img[0].cpu(), cmap='bone')\n",
        "    true_label = \"Pneumonia\" if label == 1 else \"Normal\"\n",
        "    plt.title(f\"Original: {true_label}\\nPred: {prob:.2f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # CAM overlay\n",
        "    plt.subplot(2, 4, i+5)\n",
        "    plt.imshow(img[0].cpu(), cmap='bone')\n",
        "    plt.imshow(cam, cmap='jet', alpha=0.5)\n",
        "    plt.title(f\"Grad-CAM Visualization\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('gradcam.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"Analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzAyANszg6NQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}